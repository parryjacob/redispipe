#!/usr/bin/env python2
# -*- coding: utf-8 -*-
import os
import sys
import redis
import subprocess
import hashlib
import threading
import time
import pty
import atexit
import signal


class SubprocessQueueReader(threading.Thread):
    def __init__(self, fd, rpool, rqueue):
        threading.Thread.__init__(self)
        self._fd = fd
        self._rqueue = rqueue
        self._rqueue_hist = "%s_history" % (rqueue,)
        self._redis = redis.StrictRedis(connection_pool=rpool)
        self._quiet = os.environ.get("REDISPIPE_QUIET", None) is not None
        self._queued_msgs = []
        self._last_line = None
        self._last_line_n = 0

    def _dupline(self, line):
        if self._last_line is None:
            return False
        return self._last_line == line.strip().lower()

    def _pub(self, line):
        # Check if we've published this last time
        if self._dupline(line):
            self._last_line_n += 1
            return True
        else:
            n = self._last_line_n
            self._last_line = line.strip().lower()
            self._last_line_n = 1
            if n > 1:
                # We've duplicated lines before this, tell me about them
                self._pub("Last line duplicated " + str(n - 1) + " times\n")

        try:
            self._redis.publish(self._rqueue, line)
            self._redis.lpush(self._rqueue_hist, line)
            self._redis.ltrim(self._rqueue_hist, 0, 999)

            if not self._quiet:
                print(line.rstrip())

            return True
        except redis.exceptions.ConnectionError:
            return False
        
    def run(self):
        # Publish to Redis whenever we get output
        for line in iter(self._fd.readline, b''):
            
            if len(self._queued_msgs) > 0:
                while True:
                    try:
                        qline = self._queued_msgs.pop(0)
                    except IndexError:
                        # List is empty
                        break
                    
                    if not self._pub(qline):
                        self._queued_msgs.insert(0, qline)
                        print("Couldn't publish queued line to redis!")
                        time.sleep(2)
                        continue  # This will continue the while loop, attempting to push from the queued items

            if not self._pub(line):
                self._queued_msgs.append(line)
                print("Couldn't publish to redis!")
                time.sleep(2)
                continue

    def eof(self):
        return not self.is_alive()


if __name__ == "__main__":
    if len(sys.argv) < 2:
        sys.exit(0)

    # If we run a Python application, we want it to be unbuffered or
    # we'll experience a lot of problems
    os.putenv("PYTHONUNBUFFERED", "True")
    os.environ["PYTHONUNBUFFERED"] = "True"

    # Get the command from the CLI
    cmd = sys.argv[1:]
    cmd_hash = hashlib.md5(' '.join(cmd).encode('utf-8')).hexdigest()

    # Settings are specified in the environment
    redis_url = os.environ.get("REDISPIPE_URL", "redis://127.0.0.1:6379")

    # Use the supervisord process name, if it exists
    queue_default = "redispipe_%s" % (cmd_hash,)
    if os.environ.get("SUPERVISOR_PROCESS_NAME", None) is not None:
        queue_default = "redispipe_%s" % (str(os.environ.get("SUPERVISOR_PROCESS_NAME")),)

    redis_queue = os.environ.get("REDISPIPE_QUEUE", queue_default)
    quiet = os.environ.get("REDISPIPE_QUIET", None) is not None

    if not quiet:
        print ("Redis URL: %s" % (redis_url,))
        print ("Redis queue prefix: %s" % (redis_queue,))

    # Setup the pool for our Redis connections
    rpool = redis.ConnectionPool.from_url(redis_url)

    # Create the pty's for the output
    master, slave = pty.openpty()

    # Start the desired process
    process = subprocess.Popen(cmd, stdout=slave, stderr=slave, stdin=subprocess.PIPE)
    
    # Handling SIGTERM gracefully
    def reap_proc():
        print("redispipe terminated, reaping process")
        try:
            process.terminate()
        except:
            pass
        try:
            process.kill()
        except:
            pass
    atexit.register(reap_proc)

    def sigterm_override(num, frame):
        print("SIGTERM encountered -- terminating normally")
        sys.exit()
    signal.signal(signal.SIGTERM, sigterm_override)

    stdout_fd = os.fdopen(master)

    # Publish the messages from stdout/stderr
    stdout = SubprocessQueueReader(stdout_fd, rpool, "%s_%s" % (redis_queue, "stdout"))
    stdout.daemon = True
    stdout.start()

    # Subscribe to all desired stdin
    rstdin = redis.StrictRedis(connection_pool=rpool)
    p = rstdin.pubsub(ignore_subscribe_messages=True)
    p.subscribe("%s_%s" % (redis_queue, "stdin"))

    try:
        while process.poll() is None:
            try:
                message = p.get_message()
            except redis.exceptions.ConnectionError:
                print("Can't connect to redis to get stdin!")
                time.sleep(2)
                continue
            if message is not None:
                if message['type'] == 'message' or message['type'] == 'pmessage':
                    inp = message['data']
                    process.stdin.write(inp)
                    process.stdin.write("\n")
            time.sleep(0.1)
    except KeyboardInterrupt:
        if not quiet:
            print ("Ctrl+C")
        try:
            process.terminate()
        except:
            pass
        try:
            process.kill()
        except:
            pass

    if not quiet:
        print ("----- Process Terminated -----")

    # Give it a chance to clear out the buffer
    if stdout.is_alive():
        time.sleep(1)

    # Kill out file descriptors
    try:
        stdout_fd.close()
    except:
        pass

    # Give it _another_ chance
    if stdout.is_alive():
        time.sleep(0.5)

    # Say bye to Redis
    try:
        p.unsubscribe()
    except:
        pass
